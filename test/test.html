<!DOCTYPE html>
<html>
<header>
	<title>Machine learning</title>
</header>
<body>
	<link rel="stylesheet" type="text/css" href="test1.css" />
	<div>
		<ul>
			<a href="#Overview"><li>Overview</li></a>
			<a href="#History"><li>History and relationships to other fields</li></a>
		</ul>
	</div>
	<div id="Overview">
		<h2 align="center" class="Overview">Overview</h2>
		<p align="center">The name machine learning was coined in 1959 by Arthur Samuel.Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: "A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E." This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper "Computing Machinery and Intelligence", in which the question "Can machines think?" is replaced with the question "Can machines do what we (as thinking entities) can do?". In Turing's proposal the various characteristics that could be possessed by a thinking machine and the various implications in constructing one are exposed. Machine learning tasks are classified into several broad categories. In supervised learning, the algorithm builds a mathematical model from a set of data that contains both the inputs and the desired outputs. For example, if the task were determining whether an image contained a certain object, the training data for a supervised learning algorithm would include images with and without that object (the input), and each image would have a label (the output) designating whether it contained the object. In special cases, the input may be only partially available, or restricted to special feedback.[clarification needed] Semi-supervised learning algorithms develop mathematical models from incomplete training data, where a portion of the sample input doesn't have labels.</p>
		<img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTrmTYBlquQZNUPHO6m_ggPXGWQGMkcAhKy2IMuw1ymXumO-9vZ&s"/ height="300" >
		<img src="https://www.meme-arsenal.com/memes/2226a5bb7acc453b7763de6355136716.jpg"/ height="300" >
		<img src="https://avatars.mds.yandex.net/get-zen_doc/225901/pub_5d3f198c23371c00af018d4f_5d417e301e8e3f2009575aff/scale_1200"/ height="300" >
		<img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ9U5hUAt8P2gf-Fu6cr00Q5k84Pu_qrKKB5bW8GoAZVosFffj-&s"/ height="300" >
		<h2 align="center" id="History">History and relationships to other fields</h2>
		
		<p align="center"><a href="https://en.wikipedia.org/wiki/Arthur_Samuel">Arthur Samuel</a>, an American pioneer in the field of computer gaming and <a href="https://en.wikipedia.org/wiki/Artificial_intelligence">artificial intelligence</a>, coined the term <b>"Machine Learning"</b> in 1959 while at IBM. A representative book of the machine learning research during 1960s was the Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification. The interest of machine learning related to pattern recognition continued during 1970s, as described in the book of Duda and Hart in 1973. In 1981 a report was given on using teaching strategies so that a neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal. As a scientific endeavor, machine learning grew out of the quest for artificial intelligence. Already in the early days of AI as an academic discipline, some researchers were interested in having machines learn from data. They attempted to approach the problem with various symbolic methods, as well as what were then termed "neural networks"; these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics. Probabilistic reasoning was also employed, especially in automated medical diagnosis.

		However, an increasing emphasis on the logical, knowledge-based approach caused a rift between AI and machine learning. Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation. By 1980, expert systems had come to dominate AI, and statistics was out of favor. Work on symbolic/knowledge-based learning did continue within AI, leading to inductive logic programming, but the more statistical line of research was now outside the field of AI proper, in pattern recognition and information retrieval. 755 Neural networks research had been abandoned by AI and computer science around the same time. This line, too, was continued outside the AI/CS field, as "connectionism", by researchers from other disciplines including Hopfield, Rumelhart and Hinton. Their main success came in the mid-1980s with the reinvention of backpropagation.

		Machine learning, reorganized as a separate field, started to flourish in the 1990s. The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away from the symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics and probability theory. It also benefited from the increasing availability of digitized information, and the ability to distribute it via the Internet.</p>
		
		
		

	</div>

</body>
<footer>
	
</footer>
</html>
